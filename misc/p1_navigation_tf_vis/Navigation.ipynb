{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "from agent import Agent\n",
    "from deep_q_learning import dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 0\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# Initialize the Environment\n",
    "env = UnityEnvironment(file_name=\"VisualBanana.app\")\n",
    "\n",
    "# Get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# Get the action size\n",
    "action_size = brain.vector_action_space_size\n",
    "\n",
    "# Get the state shape\n",
    "state_shape = env_info.visual_observations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_shape #21168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Agent with given hyperparameters\n",
    "\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 32         # minibatch size 8\n",
    "GAMMA = 0.99           # discount factor .99\n",
    "TAU = 1e-3#1e-3              # for soft update of target parameters\n",
    "LR = 1e-3               # learning rate 5e-4\n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "seed = 42               # random seed\n",
    "\n",
    "agent = Agent(state_shape=state_shape,\n",
    "              action_size=action_size,\n",
    "              buffer_size=BUFFER_SIZE,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              gamma=GAMMA,\n",
    "              tau=TAU,\n",
    "              learning_rate=LR,\n",
    "              update_every=UPDATE_EVERY,\n",
    "              seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer q_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer conv2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer q_network_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer conv2d_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -0.12\tEpsilon: 1.000000\n",
      "Episode 200\tAverage Score: 0.08\tEpsilon: 0.3660323\n",
      "Episode 300\tAverage Score: 0.11\tEpsilon: 0.1339807\n",
      "Episode 400\tAverage Score: -0.02\tEpsilon: 0.100000\n",
      "Episode 500\tAverage Score: -0.26\tEpsilon: 0.100000\n",
      "Episode 600\tAverage Score: 0.01\tEpsilon: 0.1000000\n",
      "Episode 611\tAverage Score: 0.06\tEpsilon: 0.100000"
     ]
    }
   ],
   "source": [
    "# Train the agent with given epsilon hyperparameters\n",
    "\n",
    "EPSILON_START = 1.0           #starting value of epsilon, for epsilon-greedy action selection\n",
    "EPSILON_MIN = 0.1            #minimum value of epsilon\n",
    "EPSILON_DECAY = 0.99           #epsilon decay factor\n",
    "EPSILON_DECAY_DELAY = 100      #used to delay the decay of epsilon by a given number of episodes\n",
    "AVERAGE_SCORE_SOLVED = 13.0   #average score needed (over 100 last episodes) to consider the environment as solved\n",
    "\n",
    "scores, num_episodes_solved = dqn(env=env,\n",
    "                                  agent=agent,\n",
    "                                  average_score_solved=AVERAGE_SCORE_SOLVED,\n",
    "                                  epsilon_start=EPSILON_START,\n",
    "                                  epsilon_min=EPSILON_MIN,\n",
    "                                  epsilon_decay=EPSILON_DECAY,\n",
    "                                  epsilon_decay_delay=EPSILON_DECAY_DELAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Episode 100\tAverage Score: 0.09\n",
    "#Episode 200\tAverage Score: 0.69\n",
    "#Episode 300\tAverage Score: 0.99\n",
    "#Episode 311\tAverage Score: 1.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the training session (scores per episode)\n",
    "\n",
    "def plot_scores(scores):\n",
    "    plt.plot(scores, color='royalblue')\n",
    "    plt.title('Scores per episode')\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('episode #')\n",
    "    plt.show()\n",
    "    \n",
    "plot_scores(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the trained agent in action.\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "\n",
    "#Uncomment these lines to use a saved checkpoint:\n",
    "#agent = Agent(state_size=state_size,\n",
    "#              action_size=action_size,\n",
    "#              buffer_size=BUFFER_SIZE,\n",
    "#              batch_size=BATCH_SIZE,\n",
    "#              gamma=GAMMA,\n",
    "#              tau=TAU,\n",
    "#              learning_rate=LR,\n",
    "#              update_every=UPDATE_EVERY,\n",
    "#              seed=seed)\n",
    "#agent.qnetwork_local.load_weights('./checkpoints/qnetwork_local.ckpt')\n",
    "\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = agent.act(state)                      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test various hyperparameters (set above) for the Agent, as well as epsilon\n",
    "def test_hyperparameters(repeat=10):\n",
    "    average_episodes_solved = 0\n",
    "    for i in range(repeat):\n",
    "        scores, num_episodes_solved = dqn(env=env,\n",
    "                                  agent=agent,\n",
    "                                  average_score_solved=AVERAGE_SCORE_SOLVED,\n",
    "                                  epsilon_start=EPSILON_START,\n",
    "                                  epsilon_min=EPSILON_MIN,\n",
    "                                  epsilon_decay=EPSILON_DECAY,\n",
    "                                  epsilon_decay_delay=EPSILON_DECAY_DELAY)\n",
    "        \n",
    "        average_episodes_solved += num_episodes_solved\n",
    "        \n",
    "    print('\\n\\nAverage number of episodes to solve: {}'.format(average_episodes_solved/repeat))\n",
    "    \n",
    "#test_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env_info.visual_observations[0]\n",
    "state=state[0]\n",
    "\n",
    "def show_image(img):\n",
    "    def scale_lumininance(img):\n",
    "        return np.dot(img[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "    def normalize(img):\n",
    "        return img / 255\n",
    "\n",
    "    img = scale_lumininance(img)\n",
    "    img = normalize(img)\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_image(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd2",
   "language": "python",
   "name": "drlnd2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
